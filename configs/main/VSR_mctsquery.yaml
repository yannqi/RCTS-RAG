# Base Config
PROJECT_NAME: VSR_MC_random_wpreFLMR_whybridRAG_woCoT_wMCTS_wreverse_retrieval_repeat5_evaluate_roll8_Top20_Top3_wextra_body_wosystemprompt
USE_RAG: True
## Dataset Config
DATASET_NAME: VSR_MC_random  # dataset name, e.g., ok, aok
DATASET_PATH:
    DATA_ROOT: ./dataspace/visual-spatial-reasoning/
## API Model Config
## CoT Path
# COT_CSV_PATH: ./logs/VSR_MC_random_Self_Cot_QwenVL2_get_CoT_steps_system_VQA_v1_trainval/outputs/trainval_pred_CoT.csv
COT_CSV_PATH: null
ENABLE_LLM_CACHE: False
LLM_MODEL_MAX_ASYNC: 20
api_extra_body:
    temperature: 0.1
    top_p: 0.001
    repetition_penalty: 1.05
    max_tokens: 512
reward_api_extra_body:
    temperature: 0.8
    top_p: 0.9
    repetition_penalty: 1.05
    max_tokens: 512

## Faiss Config
INDEX_MODEL:
    COLBELT_MODEL:
        MODEL_NAME: PreFLMR_ViT-L
        MODEL_PATH: ./cache/huggingface/hub/PreFLMR_ViT-L
        VIT_PATH: ./cache/huggingface/hub/clip-vit-large-patch14
    EMBEDDING_MODEL:
        MODEL_NAME: all-MiniLM-L6-v2
        MODEL_PATH: ./cache/huggingface/hub/all-MiniLM-L6-v2/

USE_MCTS: True
MCTS_TOP_K: 3
MCTS_ROLLOUTS: 8
TOP_K: 20

REWARD_CONFIG_DICT:
    reward_type: reverse # mutual / self / reverse
    reverse_num: 5 
    reverse_type: greedy # greedy / random / retrieval
    self_weight: 0.2 # only for mutual reward
    reverse_weight: 0.8 # only for mutual reward
    reward_loop_times: 5


INDEX_TYPE: pre_flmr
QUERY_MODE: hybrid # random \naive_text\ hybrid
FAISS_DIR: ./logs/Index_VSR_MC_random_Hybrid_Pre_Flmr/
# Other Config
DATASET_PATH_CONFIG: configs/dataset_path.yaml
TASK_CONFIG: configs/task_config.yaml

# Logger Config
WITH_TIME: False
LOG_DIR_ORI: ./logs/
SAVE_EMBEDDING_PATH: ./outputs/embedding_for_infer_hybrid_query