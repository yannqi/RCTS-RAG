# Base Config
PROJECT_NAME: New_prompt_ScienceQA_MiniLM-L6-v2_wpreFLMR_wCoT_whybridRAG_wMCTS_wmutual0208_greedy5_repeat5_evaluate_roll8_Top20_Top3_wextra_body
USE_RAG: True
## Dataset Config
DATASET_NAME: ScienceQA  # dataset name, e.g., ok, aok
DATASET_PATH:
    DATA_ROOT: ./dataspace/ScienceQA_DATA/
## API Model Config
## CoT Path
COT_CSV_PATH: ./logs/ScienceQA_QwenVL2_7B_Self_Cot_trainval/outputs/trainval_pred_CoT.csv
# COT_CSV_PATH: null
ENABLE_LLM_CACHE: False
LLM_MODEL_MAX_ASYNC: 20
api_extra_body:
    temperature: 0.1
    top_p: 0.001
    repetition_penalty: 1.05
    max_tokens: 512
reward_api_extra_body:
    temperature: 0.8
    top_p: 0.9
    repetition_penalty: 1.05
    max_tokens: 512

## Faiss Config
INDEX_MODEL:
    COLBELT_MODEL:
        MODEL_NAME: PreFLMR_ViT-L
        MODEL_PATH: ./cache/huggingface/hub/PreFLMR_ViT-L
        VIT_PATH: ./cache/huggingface/hub/clip-vit-large-patch14
    EMBEDDING_MODEL:
        MODEL_NAME: all-MiniLM-L6-v2
        MODEL_PATH: ./cache/huggingface/hub/all-MiniLM-L6-v2/

USE_MCTS: True
MCTS_TOP_K: 3
MCTS_ROLLOUTS: 8
TOP_K: 20

REWARD_CONFIG_DICT:
    reward_type: mutual # mutual / self / reverse
    reverse_num: 5 
    reverse_type: greedy
    self_weight: 0.2 # only for mutual reward
    reverse_weight: 0.8 # only for mutual reward
    reward_loop_times: 5

INDEX_TYPE: faiss_and_pre_flmr
QUERY_MODE: hybrid # random \naive_text\ hybrid
FAISS_DIR: ./logs/Index_ScienceQA_Hybrid_Pre_Flmr/
# Other Config
DATASET_PATH_CONFIG: configs/dataset_path.yaml
TASK_CONFIG: configs/task_config.yaml

# Logger Config
WITH_TIME: False
LOG_DIR_ORI: ./logs/
SAVE_EMBEDDING_PATH: ./outputs/embedding_for_infer_hybrid_query